{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<!-- # Cheatsheet on \"How to use Pandas for SQL-like actions\" \n",
    "## Part 1 - Overall review \n",
    "\n",
    "--> \n",
    "<h1 style=\"text-align:center;\" >How to use Pandas for SQL-like actions</h1>\n",
    "\n",
    "\n",
    "<h3 style=\"text-align:center;\" >Part 1 - Overall review </h3>\n",
    "\n",
    "\n",
    "<h4 style=\"font-family:courier;text-align:center;\" >Hessam Mohammad Hosseini</h4> \n",
    "<p style=\"font-family:serif;text-align:center\"\n",
    "\n",
    "<a href=\"https://github.com/jupihes\" style=\"text-align: center\" alt=\"github account\" target=\"_blank\">jupihes@github account</a> <br>\n",
    " <a href=\"mailto:hesam.mhosseini@gmail.com\">hesam.mhosseini@gmail.com</a> \n",
    "</p> \n",
    "\n",
    "<!-- <a href=\"https://github.com/jupihes\" style=\"text-align:center\"  alt=\"github account\" target=\"_blank\">\n",
    "<img src=\"GitHub_Logo.png\" alt=\"github account\" style=\"width:25px;height:25px;\">\n",
    "\n",
    " <img src=\"GitHub_Logo.png\" alt=\"https://github.com/jupihes\" width=\"34\" height=\"34\" style=\"float:left\" /> \n",
    "\n",
    "[Linkedin](https://www.linkedin.com/in/hesam-mohammad-hosseini-5a351039)\n",
    "![github](http://www.w3.org/2000/svg) \n",
    "[github](https://github.com/jupihes) <br>\n",
    "--> \n",
    "\n",
    "<!-- <a href=\"https://github.com/jupihes\">\n",
    "<img src=\"GitHub_Logo.png\" alt=\"github account\" style=\"width:250px;height:25px;\">\n",
    "</a> \n",
    "-->\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "   In this cheetsheet, I try to make readable and easy to use reference for [SQL](https://en.wikipedia.org/wiki/SQL) users aiming to explain how to do similar action in [Pandas](https://pandas.pydata.org/). My assumption is you know how to have your data as dataframe in Pandas. As soon as you have a dataframe, you can quey like table in SQL.  \n",
    "   \n",
    "   <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ed/Pandas_logo.svg\" alt=\"https://github.com/jupihes\" width=\"300\" height=\"300\" /> \n",
    "   \n",
    "<!--\n",
    "![Pandas](https://upload.wikimedia.org/wikipedia/commons/e/ed/Pandas_logo.svg) \n",
    "--> \n",
    "   \n",
    "Many possibilities are avaiable\n",
    "[IO Tools (CSV, EXCEL,DB connection â€¦)](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) but most important ones are reading from Excel and CSV. For example, following will read file address of which is `file_address`, skip first row, consider `Time` column to be parsed as `datetime` format and consider `,` as thousands identifer while reading file. \n",
    "<br>\n",
    "<br>\n",
    "`df =  pd.read_csv(file_name,skiprows=1,parse_dates=['Time'],thousands=',')`\n",
    "\n",
    "\n",
    "1. [Read csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) <br>\n",
    "<br> Functions has lots of useful options to fasilitate work. Here are options for `read_csv`. Many of :\n",
    "<br>\n",
    " <br>```df = pandas.read_csv(filepath_or_buffer, sep=', ', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None) ```<br>\n",
    " <br>\n",
    " \n",
    "2. [Read excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html#pandas.read_excel)<br> \n",
    "<br>\n",
    "Functions has lots of useful options to fasilitate work. Here are options for `read_excel`:<br>\n",
    "<br>\n",
    "```df = pandas.read_excel(io, sheet_name=0, header=0, names=None, index_col=None, parse_cols=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skip_footer=0, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds) \n",
    "```\n",
    "<br>\n",
    "\n",
    "I tried to summerized and add to what was available on [Pandas comparison with SQL](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html) aiming to simplify understanding. For details on functionality, please check and review [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. SELECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`select * `<br>`from table`|`table`  |\n",
    "| `select distinct c5 `<br>`from table` |`table['c5'].unique()`<br> or <br>`table[['c5']].drop_duplicates()`|\n",
    "| `select c1, c2,c10 `<br>`from table` |`df[[c1, c2,c10]]`  |\n",
    "| `select c10, c2, c1 `<br>`from table` |`df[[c10, c1, c2]]`  |\n",
    "| `select c10, c2*12 - c1 + c6 `<br>`from table` |`df['new c'] = df.c2*12 - df.c1 + df.c6`<br>`df[[c10,'new c']]`<br> <br> or <br> <br>`df.assign(c10 = df.c10, new_c = df.c2*12 - df.c1 + df.c6)`|\n",
    "| ` SELECT total_bill, tip, smoker, time`<br>`FROM tips`<br>`LIMIT 5`| `tips[['total_bill', 'tip', 'smoker','time']].head(5)` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update or delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|Delete| `DELETE FROM tips`<br>`WHERE tip > 9`|`tips = tips.loc[tips['tip'] <= 9]`|\n",
    "|Update|`UPDATE tips`<br>`SET tip = tip*2`<br>`WHERE tip < 2`|`tips.loc[tips['tip'] < 2, 'tip'] *= 2`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conditioning at WHERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|-| `SQL SELECT *`<br>`FROM tips`<br>`WHERE time = 'Dinner'`<br>`LIMIT 5` |`tips[tips['time'] == 'Dinner'].head(5)`<br> or<br>`is_dinner = tips['time'] == 'Dinner'`<br>`tips[is_dinner].head(5)`|\n",
    "|AND|`SELECT *`<br>`FROM tips`<br>`WHERE time = 'Dinner' AND tip > 5.00`|`tips[(tips['time'] == 'Dinner') & (tips['tip'] > 5.00)]`|\n",
    "|OR|`SELECT *`<br>`FROM tips`<br>`WHERE size >= 5 OR total_bill > 45`|`tips[(tips['size'] >= 5') or (tips['total_bill'] > 45)]`|\n",
    "|IS NULL|`SELECT *`<br>`FROM t`<br>`WHERE col2 IS NULL`|`t[t['col2'].isna()]`|\n",
    "|IS NOT NULL|`SELECT *`<br>`FROM t`<br>`WHERE col IS NOT NULL`|`t[t['col2'].notna()]`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "| ` SELECT *`<br>`FROM tips`<br>`ORDER BY tip DESC`<br>`LIMIT 10 OFFSET 5`| `tips.nlargest(10 + 5, columns='tip').tail(10)` |\n",
    "| ` SELECT total_bill, tip, smoker, time`<br>`FROM tips`<br>`ORDER BY tip DESC`<br>`LIMIT 10 OFFSET 5`| `tips[['total_bill', 'tip', 'smoker','time']] tips.nlargest(10 + 5, columns='tip').tail(10)` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GROUP BY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`SELECT sex, count(*)`<br>`FROM tips`<br>`GROUP BY sex`|`tips.groupby('sex').size()`<br>or<br>`tips.groupby('sex')['total_bill'].count()`|\n",
    "|`select A, sum(C), sum(D)`<br>`from df`<br>`group by A`|`df.groupby('A')['B','C'].sum()`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`SELECT day, AVG(tip), COUNT(*)`<br>`FROM tips`<br>`GROUP BY day`|`tips.groupby('day').agg({'tip': np.mean, 'day': np.size})`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`SELECT smoker, day, COUNT(*), AVG(tip)`<br>`FROM tips`<br>`GROUP BY smoker, day`|`tips.groupby(['smoker,'day']).agg({'tip': [np.size, np.mean]})`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`SELECT c1, COUNT(*)`<br>`FROM df`<br>`where country='IR'`<br>`GROUP BY c1`<br>`having count(*)>1000`|`df[df.country == 'IR'].groupby('c1')`<br>`.filter(lambda g: len(g) > 1000).groupby('c1').size()`|\n",
    "|`SELECT c1, COUNT(*)`<br>`FROM df`<br>`where country='IR'`<br>`GROUP BY c1`<br>`having count(*)>1000 order by count(*) desc`|`df[df.country == 'IR'].groupby('c1').filter(lambda g: len(g) > 1000)`<br>`.groupby('c1').size().sort_values(ascending=False)`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ORDER BY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|` SELECT *`<br>`FROM df`<br>`ORDER BY A, B`| `df.sort_values(['A', 'B'])` |\n",
    "|` SELECT *`<br>`FROM df`<br>`ORDER BY A desc, C`| `df.sort_values(['A', 'B'],ascending=[False, True])` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. UNION, JOIN and other set related operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will work to provide more comprehensive explanations on this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Union\n",
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`SELECT c1, c2`<br>`FROM df1`<br>`UNION ALL`<br>`SELECT c1, c2`<br>`FROM df2`|`pd.concat([df1, df2])`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between `union all` and `union` is that `union` will remove duplicates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`SELECT c1, c2`<br>`FROM df1`<br>`UNION`<br>`SELECT c1, c2`<br>`FROM df2`|`pd.concat([df1, df2]).drop_duplicates()`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5.2. Different Join cases \n",
    "I will add parts to make eplanation on `join` more clear and compehensive. Below image extracted from [Enthought](https://www.enthought.com/) named \"Enthought-Python-Pandas-Cheat-Sheets-1-8-v1.0.2\" worth more than 100 sentences to explain different types of `join`. You can get whole file via registration on [Enthought](https://www.enthought.com/).\n",
    "![Image text](Join.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|`SELECT *`<br>`FROM df1`<br>`INNER JOIN df2`<br>`ON df1.key = df2.key`|`pd.merge(df1, df2, on='key')`|\n",
    "|`SELECT *`<br>`FROM df1`<br>`INNER JOIN df2`<br>`ON df1.c7 = df2.c5`|`pd.merge(df1, df2, left_on='c7',right_on='c5')`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Time functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have possibility to use time related functionalities, we need help `Pandas` understand which columns are to be treated as time. Of course, the columns should be in for that converting them to time format is possible. For details, please check and review [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable). <br>\n",
    "If you manage to let `Pandas` know properly which column(s) to be time related column(s), they will end up having `datetime64[ns]` format. `.dtypes` on dataframe provides you with columns formats.\n",
    "Pass date related column(s) you need to `parse_dates` to `read_csv` or `read_excel` functions. Check Pandas documentation for more details.\n",
    "\n",
    "\n",
    "Doing so, you can apply `.dt` on column to have date - time selection like \n",
    "<br>\n",
    "    <br>`dt.dayofweek`\n",
    "    <br>`dt.minute`\n",
    "    <br>`dt.hour`\n",
    "    <br>`dt.second`\n",
    "    <br>`dt.quarter`\n",
    "    <br>`dt.month`\n",
    "    <br>`dt.month_name`\n",
    "    <br>`dt.weekday_name`\n",
    "    <br>`dt.weekday`\n",
    "    <br>`dt.weekofyear`\n",
    "    <br>`dt.year`\n",
    "    \n",
    "### How to get current date time using pandas?\n",
    "`pd.datetime.now()            `\n",
    "<br>`pd.datetime.now().date()`\n",
    "<br>`pd.datetime.now().year`\n",
    "<br>`pd.datetime.now().month`\n",
    "<br>`pd.datetime.now().day`\n",
    "<br>`pd.datetime.now().hour`\n",
    "<br>`pd.datetime.now().minute`\n",
    "<br>`pd.datetime.now().second`\n",
    "<br>`pd.datetime.now().microsecond`\n",
    "\n",
    "Again, check Pandas documentation for more! <br>\n",
    "<br> Here, we assume `sdate` column to have `datetime64[ns]` format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|sysdate - n| `SELECT *`<br>`FROM df`<br>`WHERE sdate> sysdate-5`|`df[df['sdate'].dt.date()>  pd.datetime.now().date()-5]`|\n",
    "|month|`SELECT *`<br>`FROM df`<br>`WHERE sdate in Q1`|`df[(df.sdate.dt.month >= 1) & (df.sdate.dt.month <= 3)]`|\n",
    "|between|`SELECT *`<br>`FROM t`<br>`WHERE to_char(sdate,'yyyy') between 1998 AND 2018`|`t[(t.sdate.dt.year >= 1998) & (t.sdate.dt.year <= 2018)]`|\n",
    "||`SELECT *`<br>`FROM t`<br>`WHERE to_char(sdate ,'day')= 'Friday'`|`df[df.sdate.dt.day_name() == 'Friday']`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. String related functionality like `like`, `Substr` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns with `string` content, we could access string related funftionality by applying `.str` on column. Here are few samples: \n",
    "<br>\n",
    "<br>`str.contains` - [contains](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html?) options :  `Series.str.contains(pat, case=True, flags=0, na=nan, regex=True)`\n",
    "<br>`str.upper`\n",
    "<br>`str.lower`\n",
    "<br>`str.extract`\n",
    "<br>`str.extractall`\n",
    "<br>`str.find`\n",
    "<br>`str.findall`\n",
    "<br>`str.len`\n",
    "<br>`str.replace`\n",
    "<br>`str.slice`\n",
    "<br>`str.split`\n",
    "<br>`str.strip`\n",
    "\n",
    "\n",
    "\n",
    "Check [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/search.html?q=.str.&check_keywords=yes&area=default) for more!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "|substr| `SELECT *`<br>`FROM tips`<br>`WHERE substr(time,1,2)  = 'Di'`|`tips[tips['time'].str[:2] == 'Di']`|\n",
    "|like|`SELECT *`<br>`FROM df`<br>`WHERE Country  like '%IR%'`|`df[df['Country'].str.contains('IR') == True]`|\n",
    "|like|`SELECT *`<br>`FROM df`<br>`WHERE Country  like 'IR%'`|`df[df['Country'].str.startswith('IR') == True]`|\n",
    "|like|`SELECT *`<br>`FROM df`<br>`WHERE Country  like '%AN'`|`df[df['Country'].str.endswith('AN') == True]`|\n",
    "|in|`SELECT *`<br>`FROM df`<br>`WHERE City in ('TEHRAN', 'BERLIN','STOKHOLM')`|`df[df['City'].isin(['TEHRAN', 'BERLIN','STOKHOLM'])`|\n",
    "|regex|`SELECT last_name`<br>`FROM contacts`<br>`WHERE REGEXP_LIKE (last_name, '^A(*)')`|`contacts[contacts['last_name'].str.contains('^A(*)')]`|\n",
    "|regex|`SELECT c1`<br>`FROM t`<br>`WHERE REGEXP_LIKE(c1,'([A-Z][\\d]{4})')`|`t[t['c1'].str.contains(([A-Z][\\d]{4}))]`|\n",
    "|regex|```SELECT upper(trim(to_char(LAC,'xxxxx')) \\\\'-' \\\\ trim(to_char(CI,'xxxxx'))) AS \"LAC-CI(HEX)\"```<br>`FROM t`|`t = t['LAC','CI'].apply(lambda x: x.astype(str).map(lambda x: int(x, base=16)))`<br>`t.assig(LAC-CI(HEX) = t['LAC']+'-'+t['CI']`|\n",
    "\n",
    "PS: Consider to replace `\\\\` with `||` in your query. `||` provide concatenation functonality in SQL, but symbol could not be rendered and I put `\\\\` for now!   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Oracle's ROW_NUMBER() analytic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SQL Sample| Pandas Sample |\n",
    "| :---:        |    :----:   |          :---: |\n",
    "| `SELECT * FROM (`<br>`SELECT t.*,`<br>`ROW_NUMBER() OVER(PARTITION BY day ORDER BY total_bill DESC) AS r`<br>`FROM tips t`<br>`)`<br>`WHERE r < 3`<br>`ORDER BY day, r;`|`(tips.assign(r=tips.sort_values(['total_bill'],ascending=False)`<br>`.groupby(['day'])`<br>`.cumcount()+1)`<br>`.query('r < 3')`<br>`.sort_values(['day', 'r']))` |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To check for missing values <br>\n",
    "- `df.notnull()` <br>\n",
    "Use to Drop Missing Values <br>\n",
    "- `df.dropna()` <br>\n",
    "Filling Missing Valuesâ€Šâ€”â€ŠDirect Replace<br>\n",
    "- `df.fillna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides [Pandas comparison with SQL](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html), I also get ideas from following references:\n",
    "1. [https://hackernoon.com/pandas-cheatsheet-for-sql-people-part-1-2976894acd0](https://hackernoon.com/pandas-cheatsheet-for-sql-people-part-1-2976894acd0)\n",
    "2. [https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e](https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e)\n",
    "3. [https://www.kaggle.com/anagharumade/thinking-like-sql-in-pandas](https://www.kaggle.com/anagharumade/thinking-like-sql-in-pandas)\n",
    "4. [https://medium.com/fintechexplained/did-you-know-pandas-can-do-so-much-f65dc7db3051](https://medium.com/fintechexplained/did-you-know-pandas-can-do-so-much-f65dc7db3051)\n",
    "5. [https://towardsdatascience.com/10-python-pandas-tricks-that-make-your-work-more-efficient-2e8e483808ba](https://towardsdatascience.com/10-python-pandas-tricks-that-make-your-work-more-efficient-2e8e483808ba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
